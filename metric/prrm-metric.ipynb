{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIT License\n",
    "\n",
    "# Copyright (c) 2025 André M. P. Mattos, Douglas A. Santos\n",
    "\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "# of this software and associated documentation files (the \"Software\"), to deal\n",
    "# in the Software without restriction, including without limitation the rights\n",
    "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "# copies of the Software, and to permit persons to whom the Software is\n",
    "# furnished to do so, subject to the following conditions:\n",
    "\n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    "\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "# SOFTWARE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Radiation Reliability Metric\n",
    "> Example calculations for PRRM on PolarFire SoC\n",
    "\n",
    "The PRRM scores are highly based on existing concepts, such as the cross section and confidence margins, and the performance reported by Embench. When reporting the PRRM, each score should be present as shown in 1., for each risk level (low, medium, and high), and obtained as 2.: \n",
    "\n",
    "1. $ PRRM_{<risk\\_level>} \\pm (PRRM_{err\\_lower}, PRRM_{err\\_upper}) $\n",
    "\n",
    "2. $ PRRM_{<risk\\_level>} = \\frac{\\sigma_{<risk\\_level>}}{EPM} \\times 10^{12} $  \n",
    "\n",
    "Where $\\sigma_{<risk\\_level>}$ 3. is the cross section for the specific risk level and $EPM$ 4. is the Embench Performance Metric, which represents the geometric average of the relative performance of the target processor with a reference processor: \n",
    "\n",
    "3. $\\sigma_{<risk\\_level>} = \\frac{N_{err~<risk\\_level>}}{fluence}$\n",
    "\n",
    "4. $EPM = \\left(\\prod_{i=1}^{n} \\frac{WPM_{ref_i}}{WPM_i} \\right)^{1/n} \\times n_{parallel}$   \n",
    "\n",
    "Where $n$ is the number of workloads, WPM stands for Workload Performance Metric 5., $ref$ is the reference platform results and parameters provided by Embench. Also, we added the $n_{parallel}$ term to the original Embench, which is the number of workloads in parallel (accounting for multi-core systems), but it is defined as 1 in this work due to a single-core benchmark implementation. $W_{time}$ is the obtained execution time, and $CPU_{freq}$ and $SF$ (Scaling Factor).\n",
    "\n",
    "5. $WPM_i = \\frac{W_{time_{~i}}}{SF_{i} \\times CPU_{freq_{~i}}}$   \n",
    "\n",
    "The $PRRM_{err\\_lower}$ and $PRRM_{err\\_upper}$ are calculated based on the uncertainty of the cross section since we assume for simplicity that EPM variation is negligible for radiation testing purposes. These error margins represent a 95\\% confidence interval for a 10\\% beam fluence uncertainty in the cross sections. Finally, we added a $10^{12}$ factor to provide scores with a more compact presentation. A lower PRRM score represents a better result as inherited by the cross section and reinforced by the EPM, which as higher, more computing performance. Therefore, it can be loosely interpreted as the probability of errors per risk level group normalized by the performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance scores and scaling factors of Embench's reference platform (Cortex-M4) and the example platform (PolarFire SoC, appcore) \n",
    "\n",
    "# Ref platform specs\n",
    "ref_platform_freq = 16     #16MHz\n",
    "ref_platform_speed = { \n",
    "    \"aha-mont64\"    : 4004,\n",
    "    \"crc32\"         : 4010,\n",
    "    \"cubic\"         : 3931,\n",
    "    \"edn\"           : 4010,\n",
    "    \"matmult\"       : 3985,\n",
    "    \"minver\"        : 3998,\n",
    "    \"nbody\"         : 2808,\n",
    "    \"nettle-aes\"    : 4026,\n",
    "    \"nettle-sha256\" : 3997,\n",
    "    \"nsichneu\"      : 4001,\n",
    "    \"slre\"          : 4010,\n",
    "    \"st\"            : 4080,\n",
    "    \"statemate\"     : 4001,\n",
    "    \"ud\"            : 3999,\n",
    "    \"wikisort\"      : 2779\n",
    "}\n",
    "ref_platform_scaling = { \n",
    "    \"aha-mont64\"    : 423,\n",
    "    \"crc32\"         : 170,\n",
    "    \"cubic\"         : 10,\n",
    "    \"edn\"           : 87,\n",
    "    \"matmult\"       : 46,\n",
    "    \"minver\"        : 555,\n",
    "    \"nbody\"         : 1,\n",
    "    \"nettle-aes\"    : 78,\n",
    "    \"nettle-sha256\" : 475,\n",
    "    \"nsichneu\"      : 1231,\n",
    "    \"slre\"          : 110,\n",
    "    \"st\"            : 13,\n",
    "    \"statemate\"     : 1964,\n",
    "    \"ud\"            : 1478,\n",
    "    \"wikisort\"      : 1\n",
    "}\n",
    "\n",
    "# MPFS specs\n",
    "mpfs_platform_freq = 600     #600MHz\n",
    "mpfs_platform_speed = { \n",
    "    \"aha-mont64\"    : 3865,\n",
    "    \"crc32\"         : 4086,\n",
    "    \"cubic\"         : 4075,\n",
    "    \"edn\"           : 4054,\n",
    "    \"matmult\"       : 4559,\n",
    "    \"minver\"        : 4017,\n",
    "    \"nbody\"         : 3805,\n",
    "    \"nettle-aes\"    : 4241,\n",
    "    \"nettle-sha256\" : 4029,\n",
    "    \"nsichneu\"      : 4083,\n",
    "    \"slre\"          : 3994,\n",
    "    \"st\"            : 4031,\n",
    "    \"statemate\"     : 4092,\n",
    "    \"ud\"            : 3963,\n",
    "    \"wikisort\"      : 4816\n",
    "}\n",
    "mpfs_platform_scaling = { \n",
    "    \"aha-mont64\"    : 698,\n",
    "    \"crc32\"         : 31,\n",
    "    \"cubic\"         : 12,\n",
    "    \"edn\"           : 11,\n",
    "    \"matmult\"       : 5,\n",
    "    \"minver\"        : 326,\n",
    "    \"nbody\"         : 3,\n",
    "    \"nettle-aes\"    : 7,\n",
    "    \"nettle-sha256\" : 146,\n",
    "    \"nsichneu\"      : 229,\n",
    "    \"slre\"          : 27,\n",
    "    \"st\"            : 85,\n",
    "    \"statemate\"     : 469,\n",
    "    \"ud\"            : 333,\n",
    "    \"wikisort\"      : 1 \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scipy\n",
      "  Downloading scipy-1.14.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Collecting numpy<2.3,>=1.23.5 (from scipy)\n",
      "  Downloading numpy-2.2.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Downloading scipy-1.14.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (40.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.2.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.1/16.1 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy, scipy\n",
      "Successfully installed numpy-2.2.1 scipy-1.14.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[64.10485077023296, 6.711043448216292, 43.40981595092025, 4.689918854090468, 3.5628880284578046, 21.922841437404543, 83.02233902759527, 3.1947744545009336, 11.434768977544383, 6.835934119259325, 9.241418946601721, 248.1728145335191, 8.755794364544201, 8.52566765244274, 21.63880813953488]\n",
      "15.183419383167744\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import gmean\n",
    "\n",
    "wpm_relative = []\n",
    "\n",
    "for workload in ref_platform_speed.keys():\n",
    "    wpm_relative.append((ref_platform_speed[workload]/(ref_platform_scaling[workload]*ref_platform_freq))/ (mpfs_platform_speed[workload]/(mpfs_platform_scaling[workload]*mpfs_platform_freq)))\n",
    "    \n",
    "print(wpm_relative)\n",
    "\n",
    "epm = gmean(wpm_relative)\n",
    "print(epm)\n",
    "\n",
    "# Just for checking, these are the reported CoreMark/MIPS scores reported by the manufacturers \n",
    "# PolarFire SoC: 3.125 CoreMarks/MHz, 1.714DMIPS/MHz\n",
    "# Reference platform: 3.42 CoreMark/MHz, 1.25 DMIPS/MHz\n",
    "\n",
    "# Now, as a comparison:\n",
    "# Coremark Score (best evaluation from manufacturers): Application cores of PolarFire SoC are 34.27 times faster than Cortex-M4 (considering freq)\n",
    "# Our example (embench with -Os optimization and not tuned): Application cores of PolarFire SoC are 15.18 times faster than Cortex-M4 (considering freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the number of errors for high, medium, and low risks \n",
    "> Considering the PolarFire SoC example with high-energy protons experiment\n",
    "\n",
    "[embench-singlecore]\n",
    "Total: 26 SEFIs\n",
    "- high-risk: \n",
    "  - hangs: 13\n",
    "  - mismatch: 2 (diagnosis: unknown)\n",
    "- medium-risk:\n",
    "  - mismatch: 1 (diagnosis: l2_cache)\n",
    "  - wdt_bad: 0\n",
    "- low-risk:\n",
    "  - wdt_good: 0\n",
    "\n",
    "[embench-freertos]\n",
    "Total: 9 SEFIs\n",
    "- high-risk: \n",
    "  - hangs: 2 \n",
    "  - mismatch: 1 (diagnosis: unknown)\n",
    "- medium-risk:\n",
    "  - mismatch: 1 (diagnosis: l2_cache/tilelink)\n",
    "  - wdt_bad: 1\n",
    "- low-risk:\n",
    "  - wdt_good: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "singlecore_fluence: 4.737303e+11\n",
      "freertos_fluence: 1.333344e+11\n"
     ]
    }
   ],
   "source": [
    "# Accumulated fluence during the experiment (after filtering) \n",
    "\n",
    "singlecore_fluence = 4.737303e+11\n",
    "freertos_fluence = 1.333344e+11\n",
    "\n",
    "print(f'singlecore_fluence: {singlecore_fluence:2e}')\n",
    "print(f'freertos_fluence: {freertos_fluence:2e}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate confidence margins\n",
    "# Author: Daniel Söderström\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Parameters (Can be sent to the functions also if wanted)\n",
    "BEAM_UNCERTAINTY = 0.1\n",
    "BITS = 4*1024*1024\n",
    "UNCERTAINTY_TABLE = np.loadtxt('./error_table_25100.txt', skiprows=2)\n",
    "\n",
    "# The table is from the ESA guidelines (ESCC 25100) how to calculate the error bars. There is certainly cleaner ways to do this, \n",
    "# but it would involve some more advanced math probably, which I haven't had the patience to go through yet\n",
    "\n",
    "# Calculate the upper and lower confidence limits (95 %) for a particle run with Nevents upsets\n",
    "# Predefine number of bits BITS, lookup table UNCERTAINTY_TABLE, and beam uncertainty BEAM_UNCERTAINTY\n",
    "# Calculate the differential uncertainty levels\n",
    "def differentialUncertaintyLevels(Nevents, beam_uncertainty = BEAM_UNCERTAINTY):\n",
    "    # delta_upper / _lower is the variance on the measured number of events.\n",
    "    if Nevents > 9999:\n",
    "        # Set the number of events to 10000 (max in table), it will be\n",
    "        #    small error bars either way, dominated by the beam uncertainty\n",
    "        Nevents = 10000\n",
    "\n",
    "    if Nevents == 0:\n",
    "        lower_limit = 0\n",
    "\n",
    "        delta_upper = UNCERTAINTY_TABLE[:, 4][0]\n",
    "        upper_limit = np.sqrt(delta_upper**2 + beam_uncertainty**2)\n",
    "    elif Nevents in UNCERTAINTY_TABLE[:, 0]:\n",
    "        # Lower limit\n",
    "        delta_upper = UNCERTAINTY_TABLE[:, 3][UNCERTAINTY_TABLE[:, 0] == Nevents]\n",
    "        lower_limit = np.sqrt((delta_upper/Nevents)**2 + beam_uncertainty**2)\n",
    "\n",
    "        # Upper limit\n",
    "        delta_upper = UNCERTAINTY_TABLE[:, 4][UNCERTAINTY_TABLE[:, 0] == Nevents]\n",
    "        upper_limit = np.sqrt((delta_upper/Nevents)**2 + beam_uncertainty**2)\n",
    "    else:\n",
    "        # Lower limit\n",
    "        DeltaBelow = UNCERTAINTY_TABLE[:, 3][UNCERTAINTY_TABLE[:, 0] < Nevents]\n",
    "        NBelow = UNCERTAINTY_TABLE[:, 0][UNCERTAINTY_TABLE[:, 0] < Nevents]\n",
    "        DeltaAbove = UNCERTAINTY_TABLE[:, 3][len(DeltaBelow)]\n",
    "        NAbove = UNCERTAINTY_TABLE[:, 0][len(DeltaBelow)]\n",
    "        DeltaBelow = DeltaBelow[-1]\n",
    "        NBelow = NBelow[-1]\n",
    "\n",
    "        # Assume piecewise linear behaviour, delta_ = k*Nevents + m\n",
    "        k = (DeltaAbove - DeltaBelow) / (NAbove - NBelow)\n",
    "        delta_lower = DeltaBelow + k*(Nevents - NBelow)\n",
    "        lower_limit = np.sqrt((delta_lower/Nevents)**2 + beam_uncertainty**2)\n",
    "\n",
    "        # Upper limit\n",
    "        DeltaBelow = UNCERTAINTY_TABLE[:, 4][UNCERTAINTY_TABLE[:, 0] < Nevents]\n",
    "        NBelow = UNCERTAINTY_TABLE[:, 0][UNCERTAINTY_TABLE[:, 0] < Nevents]\n",
    "        DeltaAbove = UNCERTAINTY_TABLE[:, 4][len(DeltaBelow)]\n",
    "        NAbove = UNCERTAINTY_TABLE[:, 0][len(DeltaBelow)]\n",
    "        DeltaBelow = DeltaBelow[-1]\n",
    "        NBelow = NBelow[-1]\n",
    "\n",
    "        # Assume piecewise linear behaviour, delta_ = k*Nevents + m\n",
    "        k = (DeltaAbove - DeltaBelow) / (NAbove - NBelow)\n",
    "        delta_upper = DeltaBelow + k*(Nevents - NBelow)\n",
    "        upper_limit = np.sqrt((delta_upper/Nevents)**2 + beam_uncertainty**2)\n",
    "    \n",
    "    try:\n",
    "        if len(lower_limit):\n",
    "            lower_limit = lower_limit.tolist()[0]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        if len(upper_limit):\n",
    "            upper_limit = upper_limit.tolist()[0]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return lower_limit, upper_limit\n",
    "\n",
    "# Calculate the cross section (this can take arrays)\n",
    "def crossSection(Nevents, fluence, bits=BITS):\n",
    "    return Nevents/(fluence * bits)\n",
    "\n",
    "# Calculate the actual uncertainty levels (suitable to e.g. plug into yerr in pyplots errorbar plot)\n",
    "# Function of number of events Nevents and fluence fluence\n",
    "def errorBars(Nevents, fluence, bits = BITS):\n",
    "    XS = crossSection(Nevents, fluence, bits=bits)\n",
    "    diff_lower, diff_upper = differentialUncertaintyLevels(Nevents)\n",
    "    if Nevents == 0:\n",
    "        lower_level = 0\n",
    "        if fluence != 0:\n",
    "            upper_level = diff_upper/(fluence * bits)\n",
    "        else:\n",
    "            upper_level = 0\n",
    "    else:\n",
    "        lower_level = XS * diff_lower\n",
    "        upper_level = XS * diff_upper\n",
    "\n",
    "    return lower_level, upper_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embench singlecore scores:\n",
      "prrm_singlecore_high:\t 2.09 ± (0.93, 1.36)\n",
      "prrm_singlecore_medium:\t 0.14 ± (0.14, 0.64)\n",
      "prrm_singlecore_low:\t 0.00 ± (0.00, 0.51)\n",
      "\n",
      "Embench freertos scores:\n",
      "prrm_freertos_high:\t 1.48 ± (1.18, 2.85)\n",
      "prrm_freertos_medium:\t 0.99 ± (0.87, 2.58)\n",
      "prrm_freertos_low:\t 0.49 ± (0.48, 2.26)\n"
     ]
    }
   ],
   "source": [
    "singlecore_highrisk = 15\n",
    "singlecore_mediumrisk = 1\n",
    "singlecore_lowrisk = 0\n",
    "\n",
    "freertos_highrisk = 3\n",
    "freertos_mediumrisk = 2\n",
    "freertos_lowrisk = 1\n",
    "\n",
    "prrm_factor = 1e12\n",
    "\n",
    "def prrm_score(Nevents, fluence):\n",
    "    prrm = (crossSection(Nevents, fluence, 1) / epm) * prrm_factor\n",
    "    diff_lower, diff_upper = differentialUncertaintyLevels(Nevents)\n",
    "    if Nevents == 0:\n",
    "        lower_level = 0\n",
    "        if fluence != 0:\n",
    "            upper_level = (prrm_factor/epm) * (diff_upper/fluence)\n",
    "        else:\n",
    "            upper_level = 0\n",
    "    else:\n",
    "        lower_level = prrm * diff_lower\n",
    "        upper_level = prrm * diff_upper\n",
    "\n",
    "    return prrm, lower_level, upper_level\n",
    "\n",
    "prrm_singlecore_high = prrm_score(singlecore_highrisk, singlecore_fluence)\n",
    "prrm_singlecore_medium = prrm_score(singlecore_mediumrisk, singlecore_fluence)\n",
    "prrm_singlecore_low = prrm_score(singlecore_lowrisk, singlecore_fluence)\n",
    "\n",
    "prrm_freertos_high = prrm_score(freertos_highrisk, freertos_fluence)\n",
    "prrm_freertos_medium = prrm_score(freertos_mediumrisk, freertos_fluence)\n",
    "prrm_freertos_low = prrm_score(freertos_lowrisk, freertos_fluence)\n",
    "\n",
    "print('Embench singlecore scores:')\n",
    "print(f'prrm_singlecore_high:\\t {prrm_singlecore_high[0]:.2f} ± ({prrm_singlecore_high[1]:.2f}, {prrm_singlecore_high[2]:.2f})')\n",
    "print(f'prrm_singlecore_medium:\\t {prrm_singlecore_medium[0]:.2f} ± ({prrm_singlecore_medium[1]:.2f}, {prrm_singlecore_medium[2]:.2f})')\n",
    "print(f'prrm_singlecore_low:\\t {prrm_singlecore_low[0]:.2f} ± ({prrm_singlecore_low[1]:.2f}, {prrm_singlecore_low[2]:.2f})')\n",
    "print('\\nEmbench freertos scores:')\n",
    "print(f'prrm_freertos_high:\\t {prrm_freertos_high[0]:.2f} ± ({prrm_freertos_high[1]:.2f}, {prrm_freertos_high[2]:.2f})')\n",
    "print(f'prrm_freertos_medium:\\t {prrm_freertos_medium[0]:.2f} ± ({prrm_freertos_medium[1]:.2f}, {prrm_freertos_medium[2]:.2f})')\n",
    "print(f'prrm_freertos_low:\\t {prrm_freertos_low[0]:.2f} ± ({prrm_freertos_low[1]:.2f}, {prrm_freertos_low[2]:.2f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Results\n",
    "> PolarFire SoC PRRM Scores\n",
    "\n",
    "Applying the PRRM to the results for high-energy proton irradiation, we obtain the scores for baremetal and FreeRTOS benchmarks. Notably, for FreeRTOS, due to the limited selection of workloads, it is less representative and is shown as a reference. \n",
    "\n",
    "##### PRRM Score of baremetal benchmark:\n",
    "\n",
    "$PRRM_{high\\_risk}$: 2.09 ± (0.93, 1.36)\n",
    "\n",
    "$PRRM_{medium\\_risk}$: 0.14 ± (0.14, 0.64)\n",
    "\n",
    "$PRRM_{low\\_risk}$: 0.00 ± (0.00, 0.51)\n",
    "\n",
    "##### PRRM Score of FreeRTOS benchmark:\n",
    "$PRRM_{high\\_risk}$: 1.48 ± (1.18, 2.85)\n",
    "\n",
    "$PRRM_{medium\\_risk}$: 0.99 ± (0.87, 2.58)\n",
    "\n",
    "$PRRM_{low\\_risk}$: 0.49 ± (0.48, 2.26)\n",
    "\n",
    "\t \n",
    "\t \n",
    "\t \n",
    "\t \n",
    "\t \n",
    "\t \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
